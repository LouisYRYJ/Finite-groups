{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5398ebd2-48ab-423a-b560-92e9d2374a0b",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71abab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "HOME = os.environ['HOME']  # change if necessary\n",
    "sys.path.append(f'{HOME}/Finite-groups/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c489f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Syntax warning: Unbound global variable in /usr/share/gap/pkg/browse/PackageIn\\\n",
      "fo.g:73\n",
      "  if not IsKernelExtensionAvailable(\"Browse\", \"ncurses\") then\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Syntax warning: Unbound global variable in /usr/share/gap/pkg/edim/PackageInfo\\\n",
      ".g:60\n",
      "  if not IsKernelExtensionAvailable(\"EDIM\",\"ediv\") then\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from itertools import product\n",
    "from jaxtyping import Float\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import copy\n",
    "import math\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "from einops import repeat\n",
    "from huggingface_hub import snapshot_download\n",
    "from huggingface_hub.utils import disable_progress_bars\n",
    "\n",
    "\n",
    "from model import MLP3, MLP4, InstancedModule\n",
    "from utils import *\n",
    "from group_data import *\n",
    "from model_utils import *\n",
    "from group_utils import *\n",
    "from irrep_bounds import *\n",
    "from bound_utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff47027",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.manual_seed(42)    # clustering depends on random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a8c4d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7254fd4f0520>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e6671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Removing unknown training parameter correct_embed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wilson/Finite-groups/src/model_utils.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(t.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection size: 14400/14400 (1.00)\n",
      "Added 14400 elements from intersection\n",
      "Added 0 elements from group 0: gapS(5)\n",
      "Taking random subset: 5760/14400 (0.40)\n",
      "Train set size: 5760/14400 (0.40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "# MODEL_DIR = '2024-08-14_21-24-30_gapS_5_'\n",
    "MODEL_DIR = '2024-09-18_23-59-00_gapS5_MLP2_128_wd2e-4_ubias'\n",
    "# MODEL_DIR = '2024-09-22_22-12-21_gapF11_MLP2_256_wd1e-4_ubias'\n",
    "# MODEL_DIR = '2024-09-23_01-06-18_A5x2_MLP2_128_wd1e-4_ubias'\n",
    "# MODEL_DIR = '2024-09-23_02-50-16_sg96_227_MLP2_128_wd1e-4_ubias'\n",
    "\n",
    "disable_progress_bars()\n",
    "local_dir = f'{HOME}/models/{MODEL_DIR}'\n",
    "if not os.path.exists(local_dir):\n",
    "    snapshot_download(repo_id=f'wiwu2390/{MODEL_DIR}', local_dir=local_dir)\n",
    "models, params = load_models(local_dir,) #sel='final')\n",
    "models = models[-1]  # get last checkpoint\n",
    "data = GroupData(params)\n",
    "group = data.groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10ba8650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118028/3089656520.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  save = t.load('../data/acc_bound_S5_new.pt')\n"
     ]
    }
   ],
   "source": [
    "save = t.load('../data/acc_bound_S5_new.pt')\n",
    "locals().update(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba60fed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:08<00:17,  3.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(models))):\n\u001b[1;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m models[instance]\n\u001b[0;32m----> 4\u001b[0m     irreps, irrep_idx_dict \u001b[38;5;241m=\u001b[39m \u001b[43mget_neuron_irreps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     irrep_idxs\u001b[38;5;241m.\u001b[39mappend(irrep_idx_dict)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/group_addition-BDyFuYvs-py3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Finite-groups/src/irrep_bounds.py:102\u001b[0m, in \u001b[0;36mget_neuron_irreps\u001b[0;34m(model, group, r2_thresh, norm_thresh)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel must be a single instance\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, MLP4):\n\u001b[0;32m--> 102\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m lneurons, rneurons, uneurons\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_neurons(squeeze\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    104\u001b[0m irreps \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39mget_real_irreps()\n",
      "File \u001b[0;32m~/Finite-groups/src/model.py:296\u001b[0m, in \u001b[0;36mMLP2.fold_linear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfold_linear\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    295\u001b[0m     lneurons, rneurons, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_neurons()\n\u001b[0;32m--> 296\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mMLP4\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     ret\u001b[38;5;241m.\u001b[39membedding_left \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(lneurons)\n\u001b[1;32m    298\u001b[0m     ret\u001b[38;5;241m.\u001b[39membedding_right \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(rneurons)\n",
      "File \u001b[0;32m~/Finite-groups/src/model.py:437\u001b[0m, in \u001b[0;36mMLP4.__init__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m--> 437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mgroup_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring_to_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_string\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    438\u001b[0m init_func \u001b[38;5;241m=\u001b[39m INITS[params\u001b[38;5;241m.\u001b[39minit_func]\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_left \u001b[38;5;241m=\u001b[39m normal(\n\u001b[1;32m    441\u001b[0m     [\n\u001b[1;32m    442\u001b[0m         params\u001b[38;5;241m.\u001b[39minstances,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m     ]\n\u001b[1;32m    446\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/group_addition-BDyFuYvs-py3.10/lib/python3.10/site-packages/jaxtyping/_decorator.py:449\u001b[0m, in \u001b[0;36mjaxtyped.<locals>.wrapped_fn_impl\u001b[0;34m(args, kwargs, bound, memos)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m TypeCheckError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Actually call the function.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_signature\u001b[38;5;241m.\u001b[39mreturn_annotation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mSignature\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# Now type-check the return value. We need to include the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# parameters in the type-checking here in case there are any\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# checking of the parameters. Unfortunately there doesn't seem\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# to be a way around that, so c'est la vie.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     kwargs[output_name] \u001b[38;5;241m=\u001b[39m out\n",
      "File \u001b[0;32m~/Finite-groups/src/group_utils.py:15\u001b[0m, in \u001b[0;36mstring_to_groups\u001b[0;34m(strings)\u001b[0m\n\u001b[1;32m     13\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings:\n\u001b[0;32m---> 15\u001b[0m     group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(group, Group):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m group\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "File \u001b[0;32m~/Finite-groups/src/named_groups.py:288\u001b[0m, in \u001b[0;36mgapS\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgapS\u001b[39m(n: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Group:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_gap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSymmetricGroup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Finite-groups/src/group.py:162\u001b[0m, in \u001b[0;36mGroup.from_gap\u001b[0;34m(gap_group, elements)\u001b[0m\n\u001b[1;32m    159\u001b[0m table \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mzeros((N, N), dtype\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m product(\u001b[38;5;28mrange\u001b[39m(N), repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# table[i, j] = int(gap_table[i, j]) - 1  # gap_table is 1-indexed\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     table[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43melements\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43melements\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43melements\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m ret \u001b[38;5;241m=\u001b[39m Group(elements, table)\n\u001b[1;32m    164\u001b[0m ret\u001b[38;5;241m.\u001b[39mgap_repr \u001b[38;5;241m=\u001b[39m gap_group\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "irrep_idxs = []\n",
    "for instance in tqdm(range(len(models))):\n",
    "    model = models[instance]\n",
    "    irreps, irrep_idx_dict = get_neuron_irreps(model, group, norm_thresh=1)\n",
    "    irrep_idxs.append(irrep_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb35478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_models = MLP2.stack(ideal_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64122e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_subidx(model, idxs):\n",
    "    if not isinstance(model, MLP4):\n",
    "        model = model.fold_linear()\n",
    "    ln, rn, un = model.get_neurons()\n",
    "    ln, rn, un = ln[:,:,idxs], rn[:,:,idxs], un[:,:,idxs]\n",
    "    ret = MLP4(model.params)\n",
    "    ret.embedding_left = nn.Parameter(ln.clone())\n",
    "    ret.embedding_right = nn.Parameter(rn.clone())\n",
    "    ret.unembedding = nn.Parameter(un.clone().mT)\n",
    "    ret.unembed_bias = nn.Parameter(model.unembed_bias.clone())\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af47d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivariance(models, group):\n",
    "    N = len(group)\n",
    "    models = models.to(device)\n",
    "    test_inputs = t.tensor(list(product(range(N), repeat=2)), device=device)\n",
    "    output = models(test_inputs)\n",
    "    stds = []\n",
    "    for i in range(N):\n",
    "        logit_vals = []\n",
    "        for j, k in product(range(N), repeat=2):\n",
    "            if group.mult_idx(j, k) == i:\n",
    "                # output is (N^2, instance, N)\n",
    "                logit_vals.append(output[N * j + k, :, i])\n",
    "        logit_vals = t.stack(logit_vals, dim=1)  # (instance, N)\n",
    "        stds.append(logit_vals.std(dim=1) / (logit_vals.mean(dim=1).abs()))   # (instance)\n",
    "        # stds.append(logit_vals.var(dim=1))   # (instance)\n",
    "    stds = t.stack(stds, dim=1)  # (instance, N)\n",
    "    return stds.mean(dim=1).nan_to_num(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d43e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_equi = equivariance(models, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9817d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_equi = equivariance(ideal_models, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "676f3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_models = MLP2(models.params)\n",
    "rand_equi = equivariance(rand_models, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adfa1f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_equi[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a4f8acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0325), tensor(1.5592e-07), tensor(15.5049))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_equi.mean(), ideal_equi.mean(), rand_equi.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35e5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAACkCAYAAACejfkrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaC0lEQVR4nO3df0wb9/0/8KcJhUCbxIBDkzQwcm5X+HxaqToHqWlLVy22lohsqyK7SFOm/sVZ2/7Ytz9ki7XTEq0dMk3W758fO39NyyaBT1GlgZLKtyodWlMV7lRp/QiqzdeMTEmbGMeQijSEcN8/+N4V8/uHwTb3fEgIfPf+Wafv1937fT8chmEYICIi2ynJdwOIiCg/GACIiGyKAYCIyKYYAIiIbIoBgIjIphgAiIhsigGAiMimGACIiGyqNN8N2AzT09O4du0aduzYAYfDke/mEBFtGMMwcPv2bezbtw8lJUsf49siAFy7dg11dXX5bgYR0aa5evUq9u/fv2QaWwSAHTt2AJj5D7Jz5848t4aIaOOMj4+jrq7OGveWYosAYE777Ny5kwGAiGxhJdPdXAQmIrIpW5wBrNfIyAhSqVROy3S5XKivr89pmUREq8EAsIyRkRE83tiEb+5MrKucPQ85EPSUIapO4suvDWyvqMTnw0MMAkSUNwwAy0ilUvjmzgRqjr2GB2rWfiXRk2XXcHLf/+Cj7/4S967fx2jvGaRSKQYAIsobBoAVeqCmDuV7Hl17fsc2q5wHJu/nqllERGvGRWAiIptiACAisikGgAI2MTEBTdMwMbG+BWgiooUwABSw4eFheDweDA8P57spRLQFMQAQEdnUpgUAt9uNTCaTtU3XdYTDYWiatqYyFUWZVyYREa3MpgWARCIBp9OZtU0QBMiyjHQ6veryNE1DIBCArus5aiERkb1sWgAQBGHB7XODwkqJorhomUREtLxNCQCapsHn81lTPbFYDLFYDF1dXVlH8Oa22WkBIBwOQ1EUHvETEeXQptwJLIoiBgcHAcwEg3g8jkQiAQCIRqMAZubzASAUCkEQBAQCASSTSWiaBl3X4fV6oWkaotEoIpHIkvXdvXsXd+/etT6Pj48DAD799FM89NBDq2r70NAQAMCYmlxVvqWYZZllL1f3nTt3clY3EZFp0x4FUV1dDQDo7u6Gz+eztptTQPF4HE6nE7FYDMDMUT8wEzzi8ThkWcbAwMCKpn06Oztx6tSpedu/973vrbn9U2NfAfv/a83555UF4MSJEytKf+XKFTz77LM5qZuIyLTpzwLSdR01NTXztqfTafh8Pvj9/qztmUwG7e3tOHv2LNLpNJLJ5LJ1dHR04NVXX7U+m2/I+fDDD9d0BnDixAmU7np4VfmWYpZ17tw5NDU1LVt3Q0NDzuomIjJtegDw+XyIRqMIhUIAYF3G2dzcjHA4DK/XC6fTCVmW4ff7rTMCp9OJZDI577LPha4gKi8vR3l5+bztTz311JrfCOYoLVtTvqXKampqgiiKy6avqKjIWd1ERKZNWwTWdR3d3d2QJAmCIMDj8SAcDkMQBGiahlAoBFEUceDAAfh8PmtgNOf+g8Eg3G43FEWBpmnWj7mWQEREq7Npi8CGYVif4/H4gukW2i6KYta0jyRJ1t+zyyQiotXhoyCIiGyKAYCIyKYYAApYY2MjVFVFY2NjvptCRFsQXwlZwCorK1d0lRAR0VrwDICIyKYYAIiIbIpTQCt0b/Tq+vKXXQP2zZRzb/R+jlpFRLR2DADLcLlc2F5RidHeM+sr6CEHTnrK8A/1HYx+bWB7RSVcLlduGklEtAYMAMuor6/H58NDSKVSOSnvR///t8vlQn19fU7KJCJaCwaAFaivr+dgTURbDheBiYhsigGAiMimGACIiGyKAYCIyKYYAIiIbIoBgIjIphgAiIhsivcBEBWpkZGRFd2gyJsOaTEMAERFaGRkBN/zNOHl/76PqDqJL79e/PWo2ysq8fnwEIMAzcMAQFSEUqkUqkq/wckXHsJH3/0lMLlvwXT3Rq9itPcMUqkUAwDNwwBAVOQeqKlDuXEg382gIsRFYCIim2IAICKyKQYAoiJ0586ddZcxMTEBTdMwMTGRgxZRMWIAICpCV65cWXcZw8PD8Hg8GB4eXn+DqChtSABwu93IZDLrTrMURVHWlZ/I7m7evAkAOHToEHbv3o2TJ0/iT3/6Ey5duoT79/naUjvYkKuAEokEnE7nutMsRtM0BAIB/PWvf4Uoimsqg8jOnE4nxsbGAACTk5NIpVI4deqUtb+hoQFnzpzB8ePH89VE2gQbcgYgCEJO0ixGFMV15Seys9mDv+nBBx/M+uxyueD3+3H+/PnNbBptslUFgFgshlgshq6uLoTDYQCALMtwu92QZRlVVVW4dOkSfD4fNE2z9nd1dSEQCCAYDCIWi0HTNCvN7Pw+nw8+ny+rznA4DEVREAgEoOt6jrpNZE83b960Bv+nn34aAPD8889jfHw8KyjcuHEDra2teP311zkdtIWtOAAoioJ4PA5JkhAKhaDrOrq6uuD1eqHrOkRRhKqqeOGFFzA4OGjla29vRygUQiQSQU9PDyRJgiiKVhq/32/lTyQSGBwctAZ6TdOg6zq8Xi+am5sRjUZX1Na7d+9ifHw864fIjoypSQDA0NAQNE3DU089Ze17/PHHAQA/+clPUFJSgp07d6KpqQnAzKMmjhw5gi+++AL9/f2b3m7aHCsOAIlEImu+3efzobu725rHFwTBmpaprq4GAGQyGetn7pSNmcZk7hcEwQoAoigiHo9DlmUMDAysuFOdnZ3YtWuX9VNXV7fivERbydTYVwCAEydOwOPx4Nq1a9a+P/zhDwCA0tJvlwLffvtt6++KigoAwPXr1zejqZQHq5oCmn3VTXV19bxBfC6n04lIJIJwOIxYLIazZ8+uqnGZTAaBQABer3fe1NBSOjo6MDY2Zv1cvXp1VfUSbRWlux4GAJw7dw6qqmLfvm+fGfTyyy8DAKampqxtb7zxhvW3ea/B3r17N6OplAcrvgqora0Nhw8ftqZhBgYGEAgEVnQp5kqnbuaKxWIAZgJJMpmcV1c6nV4wX3l5OcrLy9dUJ9FW4igtAwA0NTVBFEV8+umnqK2tBQB8/vnnAIA///nPaG9vx9dff42hoSEAQH19PS5evIgDBw6gpaUlP42nDbfiMwBRFK2jeVmWUVNTA0mS0NPTA+Dbwdqct+/u7gYwM/hXVVXB7XZbC7mz0yiKAmBmjUHXdei6jkQiAQDwer3QNA3BYBButxuKokDTNOvHTEdEK7N7927s2rULAPDxxx8DAP72t79hx44d1nYAqK2tRV9fH06fPo1t27blpa208VZ1H4AkSQtum71dFEUYxsyzyXVdRyQSgdfrRTqdRiaTgSzLCIVCVhoAWX/funUrq6xkMrlg/bPzENHKZTKZeZeCzn0cxOjoKGRZ5n0AW9yGPg46EonA6XTC6/WiurrautqHiPIrk8ng/fffx5EjR1BWVoadO3fiF7/4BR577DE88sgjaGlp4ZG/DWx4AIjFYmhvb4cgCAgGg7yBi6hA7N69GwBw+fJlHpjZ1IYGAKfTiVAotJFVENlSQ0PDustobGyEqqpobGxcf4OoKPGNYERFyLxGfz0qKyt55G9zfBw0EZFNMQAQEdkUAwARkU1xDYCoyN0bvYq7kws/sfPeKB+DQotjACAqQi6XC7emtuPkpbv4h/oOvvx68Rsjt1dUwuVybWLrqFgwABAVofr6enyoDiGVSuFHy6R1uVyor6/flHZRcWEAICpS9fX1HNhpXbgITERkUwwAREQ2xQBARGRTDABERDbFAEBEZFMMAERENsXLQIloyxkZGUEqlVo2nd3vkWAAIKItZWRkBI83NuGbOzOvudzzkANBTxmi6uS8O6a3V1Ti8+Eh2wYBBgAi2lJSqRS+uTOBmmOv4YGaOjxZdg0n9/0PPvruL4HJfVa6e6NXMdp7BqlUigGAiGgreaCmDuV7HsUDjm3ffjYO5LlVhYWLwERENsUAQERkUwwARFS0JiYmoGkaJiYmiqLcQsMAQERFa3h4GB6PB8PDw0VRbqFhACAisqm8XQWk6zqi0Sja2togimK+mkFENM/k5CQAIBKJ4NChQ/j5z3+Obdu2ob+/H9evX0dtbS0A4MaNG9i7dy+eeeYZ9Pf344MPPsDIyAj2798Pl8uFPXv24JFHHsEzzzyDjz76CNevX8fevXvR0tKCbdu2WfXdv3/fKtssb6n0uZK3ACAIAmRZhs/ny1cTiIjmCYVC+P3vfw8A6OnpQU9PD1577TXs2LEDY2NjC+YpKSnB9PT0omWWlpZiamrK+tzQ0IAzZ87g+PHjOH/+PF577TVcuXJlRelzKa9TQE6nM5/VExFlCYVCeOedd7Br1y4AwPvvv4+f/exnmJ6extjYGFpaWgAAzz33HJ577jk4HA4AsAb/vXv3AgCqqqqyyn3wwQfhcDhw7tw5XL58GU8++ST8fj9CoRD8fj+efPJJXL58GefOnYPD4UBNTQ0AzEt//vz5nPZ3VQFAlmW43W7IsoyqqipkMhmEw2EoioJAIABd1+el8/l8WUf5sVgMsVgMXV1dVvq528PhMABAURSrnGAwCI/HA03TEA6H4Xa7oShKLv4bEBFhcnIS7777Lh5++GFcuHABwMxAfuHCBRw7dgy1tbXo7+9Ha2srPvzwQ3zwwQfYvn07HA4HysrKUFtbi5s3b+LYsWO4ceMGWltb4XA4UFJSAqfTidbWVvz6179Gc3Mz3nvvPbS2tuLdd99Fa2sr3nvvPTQ3N+PNN9/EsWPH8J///Ac//OEPs9IfO3YMr7/+Ou7fv5+zPq8qAHi9Xui6DlEUoaoqdF2Hruvwer1obm5GNBoFAPj9fitdIpHA4OAgdF2HpmmIx+OQJAmhUAjV1dUAZgb62dt1XUdXV5dVnyAIiEajqK6uRnd3NyKRCCKRiFXfXHfv3sX4+HjWDxFtPXfu3AEADA0NQdM0aJqGoaEhAIAxNblkXnO/mbejowNTU1Nob2/HP//5TwDAxx9/jCtXruCNN97AiRMnAACPPvooSkpK8Pe//x137tyBYRiYnJzET3/6U0xNTeHo0aMoLS3F0aNHYRgGpqen8e9//xtHjhzBF198gf7+fpSUlODIkSNW+pKSEvT39+PKlSv41a9+hdLSUnR0dGSln/05V1a1BmBO2QiCYG2Lx+OQZRkDAwNZ22enEwQBuq4jkUhknQ2Y5SUSiayFYJ/Ph2g0ilAoBKfTmVWO2+228s4+g5its7MTp06dWk3XiKgImfPm5uA829TYV8D+/1o079TYVwvmfeutt6y/zctAn3jiCaiqCuDboHP9+vWsfOY4VVFRkfXbZH42881NZ25/4oknsn7P3T633vVY1xpAJpNBIBCA1+td0WLuYgO2WZapurraOjtYi46ODoyNjVk/V69eXXNZRFS4GhoaAMzMlauqClVVce7cOQBA6a6Hl8xr7jfzvvrqqwCAN9980yqjsbERAPDZZ59Z45c5YJvz/SZzvxkgzN8m87OZb246c/tnn32W9Xvu9rn1rseqAsDsQRqYmbcHZo7Gk8nkvP1z+Xw+dHd3zyuvra0NPT091vaBgQEEAoEF61yuDgAoLy/Hzp07s36IaOsxB+OmpiaIoghRFNHU1AQAcJSWLZnX3G/m7ezsRGlpKc6ePYvHHnsMAPD000+joaEBb7/9thUU/vWvf2F6ehrPPvssKioqrDWAP/7xjygtLcWFCxcwNTWFCxcuWGsA3/nOd3Dx4kUcOHAALS0tmJ6exsWLF63009PTaGlpQUNDA373u99hamoKnZ2dWelnf86VVQUAc5A2B36v1wtN0xAMBq1FWU3TrMVZRVGsdYJEIgFJkiAIAjweD8LhMARBgKZpEEURkUgE4XAYsiyjpqYGkiRZ5fT09CCTyWBwcBCJRAKZTAaJRMIqm4hovcrKyvDKK6/gq6++wtGjRwEA6XQaP/jBD9Db24sbN26gpaUFfX19eP755/H9738f33zzjbUGcOPGDezevRu9vb2ora1FX1+ftQaQyWTQ19eH3/72t/jkk0/w4osvoq+vD6+88gr6+vrw4osv4pNPPsFbb72F3t5e7N+/H3/5y1+y0vf29uL06dM5vR/AYRiGsXyy4jY+Po5du3ZhbGyMZwNEW4imafB4PFBV1VpHNLftefn/onzPo/hvxxfoK38DrXffxv/Oehz03S//hS//8H+y8gLf3gcw+2qbkpKSnN4HcODAAZw+fXrF9wHMTr+c1Yx3fB8AEdEsXV1dOH78OA4dOoSXXnppw+8EPn78OH784x/b605gIqJCVVY2sz4QDoezzg5eeOGFRfMcPnwYhw8fXnT/Unm3bds2b/9S6XOFD4MjoqLV2NgIVVWtq3UKvdxCwzMAIipalZWVG/IwyY0qt9DwDICIyKYYAIiIbIpTQES0Jd0bnXkCwL2ya8C+mc93J+/P229nDABEtKW4XC5sr6jEaO+ZmQ0POXDSU4Z/qO/gy6+zb3vaXlEJl8uVh1YWBgYAItpS6uvr8fnwEFKpVNb2Hy2Q1uVyob6+fnMaVoAYAIhoy6mvr7f1wL5SXAQmIrIpW5wBmI874othiGirM8e5lTzmzRYB4Pbt2wCAurq6PLeEiGhz3L5923q38WJs8TTQ6elpXLt2DTt27LBe4rzVjI+Po66uDlevXt3STzy1Sz8B+/SV/cwtwzBw+/Zt7Nu3DyUlS8/y2+IMoKSkBPv37893MzaFXV6AY5d+AvbpK/uZO8sd+Zu4CExEZFMMAERENsUAsEWUl5fjN7/5DcrLy/PdlA1ll34C9ukr+5k/tlgEJiKi+XgGQERkUwwANhKLxaAoSr6bsSk0TUMwGMx3MzZMJpNBIBBAVVUVurq68t2cnAqHw1AUZcv1a65C+A4ZAGwiGAzi4MGD8Hq9+W7Kpuju7s53EzaUoiiIx+O4desWOjs7892cnJFlGW63G16vF6Ojo9A0Ld9N2jCF8B3a4j6AYpTJZBCLxZBMJhGNRq3tiqIgkUjA7XYDACRJWrYsRVGg6zoGBwcBoOBedZfLvgIzg0hbW1tWWYUgl/30+/3W3wcPHsx9Y3NoNf3u7u5GR0cHAMDtdkNRlIL797qU1fS1EL5DBoAC5XQ64XQ6oet61vZwOAxVVQEAPp8PBw8eXPZ/kEQiAZ/Ph5deegmHDx9GPB6HIAgb1vbVymVfNU0r2AEjl/00ZTIZ+Hy+nLc1l1bT70wmA6fTCQCorq5GMpnc7Oauy1q+43x+hwwABay6ujrrcywWyxq4fT4fotEootEoZFmel18QBIiiiEwmg7a2NjidTrS1tUFRlBUfTW+WXPU1HA5DEASk02lomgZZlrOOtPItV/2cnT8UCm1cg3Nkpf12Op3IZDIAgHQ6jZqams1sZk6s5js29+frO2QAKCKqqmb9QxIEwZrrXmqQ83g8GBwctAaOuf9AC9Fa+5pIJAAAuq4jEokU1OC/kLX2E5iZ6jID+ewj52KwWL+DwSB0XYcoikgmk2hra8tjK3Njqe84398hF4GLyNwjotlHS0uRJAnJZBKyLGN0dLTgB0Vg7X0tNmvtpyzLCIfDCAQC8Hg886YcCt1i/ZYkCQMDA1AUBTU1NQU7nbcai/W1EL5DngEUkerqaoyOjlqfV3PEEIlEACx/VFko1tNXYOYoq9AWgRey1n76/f6i+S4XslS/zX+rW+WKtcX6WgjfIc8Aisjco4R0Ol3wV4CslV36apd+zmWnfhdyXxkAiogkSVnXRScSCQQCgTy2aOPYpa926edcdup3IfeVzwIqUJlMBu3t7dA0DfF43JoLVRQFmqZZ84jFcAXIcuzSV7v0cy479bvY+soAQERkU5wCIiKyKQYAIiKbYgAgIrIpBgAiIptiACAisikGACIim2IAoKKnaRrcbrf1ZqVgMIhAIJB196Xb7d7wZwnluo7NaDPZG+8DoC0hGAwinU4jHo8DmHn+uqZpWU8H3eh3IOS6js1oM9kbzwBoS3K73VlnAJsxkOa6Dg7+tNEYAGjL0XUd0WjUeim8pmnw+XyLvl82Fouhq6trXhpZlhGLxRCLxRAIBKAoCmKxGKqqqqxyHQ4HdF2fV4csy3A4HFAUxaojHA4D+Pal57Onqcx34cqyjKqqKly6dCmrvOXy+Hy+rLdKmW0Ph8OIxWLL9pVsyiDaAiRJMgRBMCRJMkRRNERRNJLJpLXf6XQaqqrOy5dIJIxoNGoYhmHE43FDEATDMAxDVVVDkiQrnSAIRiKRMJLJpOF0OrO2m/XMrcPr9Vplm79VVTX8fr9hGIYRiUSMUChkGIZh3Lp1ywBgJJPJeeUtlscwDCuPmT6ZTBqJRMJqezKZtPIu1leyL54B0JYhiiKi0ShUVUVbW1vWIupib0GLx+NIJpOIxWJIp9PWUXo0GoXH47HSzX5P7WLm7gsGg9Y7Ccx2iKKIeDwOWZYxMDAwr3xBEKypH7O8xfKYzPSCIEDXdcTjcetsQBAEa11ksb6SffGFMLQlSZKEcDiMwcHBrBeLxGIxa1A2F459Pt+8F3Ok0+l1X4Hj9/vR3t4OWZatNphPizx79izS6fSKXnq+2jzpdBrpdHrB7Qv1leyLZwC0JZlz73MXUiVJgqqqUFUVkiShubkZ4XDYGuzNF7E3Nzdb720FkBUMzL8zmQx0XV/yVX6SJKGzs9N6LLA5H+90OpFMJrPKWsxieRbj8/kQiUSsdGb+xfpKNpbvOSii9VJV1RAEwXA6ndYcuSiKRjwet/YDyJo7n83v9xtOp9Pwer1Z6wZer9cQBMEqL5FIGIZhWJ9DoZDh9XoNSZIWrePWrVtGJBKZ11ZJkoxoNGoIgmCoqmpEo1EDQNZagVneYnkSiYQBIGttwqxfkiTD6XTOWwtZrK9kT7wPgGgFPB4PIpHIlnlPLRHAKSCiZa1kqoeoGHERmGgZ6XQaqqrmuxlEOccpICIim+IUEBGRTTEAEBHZFAMAEZFNMQAQEdkUAwARkU0xABAR2RQDABGRTTEAEBHZFAMAEZFN/T/Lec8+nPTTFgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 400x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('font', family='serif', serif='Times')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('xtick', labelsize=9)\n",
    "plt.rc('ytick', labelsize=9)\n",
    "plt.rc('axes', labelsize=9)\n",
    "\n",
    "width = 4.0\n",
    "height = 1.5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.2, bottom=.26, right=.99, top=.97)\n",
    "\n",
    "all_equi = [rand_equi.tolist(), orig_equi.tolist(), ideal_equi.tolist()]\n",
    "bp = plt.boxplot(all_equi, patch_artist=True, tick_labels=['random', 'original', 'ideal'], vert=False, widths=0.7)\n",
    "plt.xscale('log')\n",
    "fig.set_size_inches(width, height)\n",
    "plt.xlabel('Bi-equivariance')\n",
    "fig.savefig('../figs/equivariance_S5.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e655f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_model = ideal_models[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1a2b407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel = model_subidx(ideal_model, irrep_idxs[13]['1d-0'])\n",
    "# submodel.unembed_bias = nn.Parameter(t.zeros_like(submodel.unembed_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "83628e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0003])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equivariance(ideal_model, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aeb7002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0003])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equivariance(submodel, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "df5c19a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1d-0': [91, 111, 122],\n",
       " '4d-0': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  47,\n",
       "  48,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  89,\n",
       "  90,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  123,\n",
       "  124,\n",
       "  127],\n",
       " '5d-0': [],\n",
       " '6d-0': [],\n",
       " '5d-1': [],\n",
       " '4d-1': [],\n",
       " '1d-1': []}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrep_idxs[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bd932e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d-0\n",
      "1-r2 90th percentile 0.0\n",
      "a variance: 0.0\n",
      "b variance: 0.8888888955116272\n",
      "c variance: 0.8888888955116272\n",
      "d variance: 0.0\n",
      "a vs d tensor(0.)\n",
      "b_hat diff tensor(0.)\n",
      "c_hat diff tensor(0.)\n",
      "b_mean tensor([[-1.]])\n",
      "c_mean tensor([[1.]])\n",
      "\n",
      "4d-0\n",
      "1-r2 90th percentile 0.049977101385593414\n",
      "a variance: 0.5120246410369873\n",
      "b variance: 0.9888470768928528\n",
      "c variance: 0.996042013168335\n",
      "d variance: 0.5120441317558289\n",
      "a vs d tensor(8.9390e-06)\n",
      "b_hat diff tensor(0.1062)\n",
      "c_hat diff tensor(0.1062)\n",
      "b_mean tensor([[-0.0112, -0.2582, -0.0610,  0.8989]])\n",
      "c_mean tensor([[ 0.0093,  0.2550,  0.0618, -0.8998]])\n",
      "\n",
      "5d-0\n",
      "6d-0\n",
      "5d-1\n",
      "4d-1\n",
      "1d-1\n",
      "UNIF VECS 1d-0\n",
      "coef tensor([1.1321, 1.1658, 0.0464])\n",
      "unif_coef tensor([1.1490, 1.1490, 0.0000])\n",
      "UNIF VECS 4d-0\n",
      "4d-0 zeroed 19 106 stab 12\n",
      "coef tensor([3.1721, 0.7348, 0.6512, 1.5985, 2.8507, 0.6964, 1.4886, 1.2925, 2.0700,\n",
      "        0.4959, 1.9167, 1.3636, 1.4105, 1.9773, 1.9568, 0.2555, 0.6615, 0.7733,\n",
      "        1.6255, 2.4068, 2.7403, 0.2055, 2.5728, 1.1255, 1.5742, 2.6145, 2.2485,\n",
      "        0.2988, 0.7034, 0.9031, 1.2072, 0.5275, 0.4086, 1.4303, 2.0427, 2.1786,\n",
      "        2.8081, 1.6241, 2.5420, 0.2960, 0.4142, 2.9095, 2.4875, 2.6036, 2.6250,\n",
      "        2.2887, 1.9398, 0.5739, 1.5128, 2.2947, 1.9995, 0.2053, 1.7292, 0.1111,\n",
      "        2.6658, 2.1171, 1.7427, 1.1722, 2.3420, 1.4843, 1.9018, 1.7774, 1.3848,\n",
      "        1.5565, 1.0111, 1.2211, 1.5781, 1.3100, 2.2673, 1.1839, 2.6316, 1.0965,\n",
      "        2.3469, 2.0303, 0.4492, 0.4306, 1.4300, 2.2133, 1.8072, 0.4167, 0.3416,\n",
      "        1.8783, 0.3285, 0.4904, 2.2719, 1.2732, 1.9552, 0.4041, 2.7499, 2.0713,\n",
      "        2.3559, 2.6477, 0.3105, 1.6094, 2.0000, 1.0014, 1.7148, 0.5373, 2.5899,\n",
      "        2.4160, 0.9130, 1.4304, 2.7449, 2.5277, 1.1812, 0.2694])\n",
      "unif_coef tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "GET_IDEALIZED_MODEL 1d-0\n",
      "l diff tensor(0.0205)\n",
      "r diff tensor(0.0205)\n",
      "u diff tensor(0.0057)\n",
      "GET_IDEALIZED_MODEL 4d-0\n",
      "l diff tensor(1.)\n",
      "r diff tensor(1.)\n",
      "u diff tensor(0.)\n",
      "total\n",
      "l 1-r2 tensor(0.9594)\n",
      "r 1-r2 tensor(0.9594)\n",
      "u 1-r2 tensor(0.0003)\n",
      "bias 1-r2 tensor(0.5477)\n"
     ]
    }
   ],
   "source": [
    "model = models[13]\n",
    "irreps, irrep_idx_dict = get_neuron_irreps(model, group, norm_thresh=0.1)\n",
    "vecs, avar = get_neuron_vecs(model, group, irreps, irrep_idx_dict, strict=False, num_clusters=1, verbose=True, stab_thresh=0.3)\n",
    "# irrep_acc, irrep_time, all_zeroed = irrep_acc_bound(model, group, irreps, irrep_idx_dict, vecs)\n",
    "unif_vecs, zeroed_irreps = get_unif_vecs(group, irreps, vecs, verbose=True, stab_thresh=0.3)\n",
    "ideal, _ = get_idealized_model(model, irreps, irrep_idx_dict, unif_vecs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "908e4e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equivariance(ideal, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "61b6d6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal.unembed_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9a86e8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,\n",
       "           1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257,\n",
       "          -1.1257, -1.1257,  1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257,\n",
       "          -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "           1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,  1.1257,\n",
       "          -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "           1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,\n",
       "           1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          -1.1257,  1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,\n",
       "           1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257,\n",
       "          -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,  1.1257, -1.1257,\n",
       "          -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257,\n",
       "          -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "           1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,\n",
       "           1.1257]]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submodel(t.tensor([[0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9473f2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722,\n",
       "          -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,\n",
       "           1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,\n",
       "           1.1722,  1.1722, -1.1722,  1.1722, -1.1722, -1.1722,  1.1722,\n",
       "           1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,\n",
       "           1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722,\n",
       "          -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722, -1.1722,\n",
       "           1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722,\n",
       "          -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722,\n",
       "          -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,\n",
       "           1.1722, -1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722,\n",
       "          -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,\n",
       "           1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,\n",
       "           1.1722,  1.1722, -1.1722, -1.1722,  1.1722, -1.1722,  1.1722,\n",
       "           1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,\n",
       "           1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722,\n",
       "          -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722,\n",
       "          -1.1722]]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submodel(t.tensor([[15, 27]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed0b47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14400, 1, 120])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs = t.tensor(list(product(range(data.N), repeat=2)), device=device)\n",
    "models[0](test_inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03cc9b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groups[0].mult_idx(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "809c66e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 2],\n",
       "        [0, 3],\n",
       "        [0, 4],\n",
       "        [0, 5],\n",
       "        [0, 6],\n",
       "        [0, 7],\n",
       "        [0, 8],\n",
       "        [0, 9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262824d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group_addition-BDyFuYvs-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
