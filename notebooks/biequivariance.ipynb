{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5398ebd2-48ab-423a-b560-92e9d2374a0b",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71abab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "HOME = os.environ['HOME']  # change if necessary\n",
    "sys.path.append(f'{HOME}/Finite-groups/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c489f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from itertools import product\n",
    "from jaxtyping import Float\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import copy\n",
    "import math\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "from einops import repeat\n",
    "from huggingface_hub import snapshot_download\n",
    "from huggingface_hub.utils import disable_progress_bars\n",
    "\n",
    "\n",
    "from model import MLP3, MLP4, InstancedModule\n",
    "from utils import *\n",
    "from group_data import *\n",
    "from model_utils import *\n",
    "from group_utils import *\n",
    "from irrep_bounds import *\n",
    "from bound_utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff47027",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.manual_seed(42)    # clustering depends on random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a8c4d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x73b7000a2ef0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e6671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Removing unknown training parameter correct_embed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wilson/Finite-groups/src/model_utils.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(t.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection size: 14400/14400 (1.00)\n",
      "Added 14400 elements from intersection\n",
      "Added 0 elements from group 0: gapS(5)\n",
      "Taking random subset: 5760/14400 (0.40)\n",
      "Train set size: 5760/14400 (0.40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "# MODEL_DIR = '2024-08-14_21-24-30_gapS_5_'\n",
    "MODEL_DIR = '2024-09-18_23-59-00_gapS5_MLP2_128_wd2e-4_ubias'\n",
    "# MODEL_DIR = '2024-09-22_22-12-21_gapF11_MLP2_256_wd1e-4_ubias'\n",
    "# MODEL_DIR = '2024-09-23_01-06-18_A5x2_MLP2_128_wd1e-4_ubias'\n",
    "# MODEL_DIR = '2024-09-23_02-50-16_sg96_227_MLP2_128_wd1e-4_ubias'\n",
    "\n",
    "disable_progress_bars()\n",
    "local_dir = f'{HOME}/models/{MODEL_DIR}'\n",
    "if not os.path.exists(local_dir):\n",
    "    snapshot_download(repo_id=f'wiwu2390/{MODEL_DIR}', local_dir=local_dir)\n",
    "models, params = load_models(local_dir,) #sel='final')\n",
    "models = models[-1]  # get last checkpoint\n",
    "data = GroupData(params)\n",
    "group = data.groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "10ba8650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12705/3089656520.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  save = t.load('../data/acc_bound_S5_new.pt')\n"
     ]
    }
   ],
   "source": [
    "save = t.load('../data/acc_bound_S5_new.pt')\n",
    "locals().update(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba60fed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:24<00:00,  4.16it/s]\n"
     ]
    }
   ],
   "source": [
    "irrep_idxs = []\n",
    "for instance in tqdm(range(len(models))):\n",
    "    model = models[instance]\n",
    "    irreps, irrep_idx_dict = get_neuron_irreps(model, group, norm_thresh=1)\n",
    "    irrep_idxs.append(irrep_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb35478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_models = MLP2.stack(ideal_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64122e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_subidx(model, idxs):\n",
    "    if not isinstance(model, MLP4):\n",
    "        model = model.fold_linear()\n",
    "    ln, rn, un = model.get_neurons()\n",
    "    ln, rn, un = ln[:,:,idxs], rn[:,:,idxs], un[:,:,idxs]\n",
    "    ret = MLP4(model.params)\n",
    "    ret.embedding_left = nn.Parameter(ln.clone())\n",
    "    ret.embedding_right = nn.Parameter(rn.clone())\n",
    "    ret.unembedding = nn.Parameter(un.clone().mT)\n",
    "    ret.unembed_bias = nn.Parameter(model.unembed_bias.clone())\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "af47d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivariance(models, group):\n",
    "    N = len(group)\n",
    "    models = models.to(device)\n",
    "    test_inputs = t.tensor(list(product(range(N), repeat=2)), device=device)\n",
    "    output = models(test_inputs)\n",
    "    stds = []\n",
    "    for i in range(N):\n",
    "        logit_vals = []\n",
    "        for j, k in product(range(N), repeat=2):\n",
    "            if group.mult_idx(j, k) == i:\n",
    "                # output is (N^2, instance, N)\n",
    "                logit_vals.append(output[N * j + k, :, i])\n",
    "        logit_vals = t.stack(logit_vals, dim=1)  # (instance, N)\n",
    "        stds.append(logit_vals.std(dim=1) / (logit_vals.mean(dim=1).abs()))   # (instance)\n",
    "        # stds.append(logit_vals.var(dim=1))   # (instance)\n",
    "    stds = t.stack(stds, dim=1)  # (instance, N)\n",
    "    return stds.mean(dim=1).nan_to_num(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "66d43e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_equi = equivariance(models, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9817d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_equi = equivariance(ideal_models, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "676f3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_models = MLP2(models.params)\n",
    "rand_equi = equivariance(rand_models, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "adfa1f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0003)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_equi[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9a4f8acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0325), tensor(1.5592e-07), tensor(97.4341))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_equi.mean(), ideal_equi.mean(), rand_equi.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "eb35e5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('font', family='serif', serif='Times')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('xtick', labelsize=9)\n",
    "plt.rc('ytick', labelsize=9)\n",
    "plt.rc('axes', labelsize=9)\n",
    "\n",
    "width = 4.0\n",
    "height = 1.5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.2, bottom=.26, right=.99, top=.97)\n",
    "\n",
    "all_equi = [rand_equi.tolist(), orig_equi.tolist(), ideal_equi.tolist()]\n",
    "bp = plt.boxplot(all_equi, patch_artist=True, tick_labels=['random', 'original', 'ideal'], vert=False, widths=0.7)\n",
    "plt.xscale('log')\n",
    "fig.set_size_inches(width, height)\n",
    "fig.savefig('../figs/equivariance_S5.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e655f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_model = ideal_models[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1a2b407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel = model_subidx(ideal_model, irrep_idxs[13]['1d-0'])\n",
    "# submodel.unembed_bias = nn.Parameter(t.zeros_like(submodel.unembed_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "83628e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0003])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equivariance(ideal_model, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aeb7002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0003])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equivariance(submodel, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "df5c19a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1d-0': [91, 111, 122],\n",
       " '4d-0': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  47,\n",
       "  48,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  89,\n",
       "  90,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  123,\n",
       "  124,\n",
       "  127],\n",
       " '5d-0': [],\n",
       " '6d-0': [],\n",
       " '5d-1': [],\n",
       " '4d-1': [],\n",
       " '1d-1': []}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrep_idxs[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bd932e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d-0\n",
      "1-r2 90th percentile 0.0\n",
      "a variance: 0.0\n",
      "b variance: 0.8888888955116272\n",
      "c variance: 0.8888888955116272\n",
      "d variance: 0.0\n",
      "a vs d tensor(0.)\n",
      "b_hat diff tensor(0.)\n",
      "c_hat diff tensor(0.)\n",
      "b_mean tensor([[-1.]])\n",
      "c_mean tensor([[1.]])\n",
      "\n",
      "4d-0\n",
      "1-r2 90th percentile 0.049977101385593414\n",
      "a variance: 0.5120246410369873\n",
      "b variance: 0.9888470768928528\n",
      "c variance: 0.996042013168335\n",
      "d variance: 0.5120441317558289\n",
      "a vs d tensor(8.9390e-06)\n",
      "b_hat diff tensor(0.1062)\n",
      "c_hat diff tensor(0.1062)\n",
      "b_mean tensor([[-0.0112, -0.2582, -0.0610,  0.8989]])\n",
      "c_mean tensor([[ 0.0093,  0.2550,  0.0618, -0.8998]])\n",
      "\n",
      "5d-0\n",
      "6d-0\n",
      "5d-1\n",
      "4d-1\n",
      "1d-1\n",
      "UNIF VECS 1d-0\n",
      "coef tensor([1.1321, 1.1658, 0.0464])\n",
      "unif_coef tensor([1.1490, 1.1490, 0.0000])\n",
      "UNIF VECS 4d-0\n",
      "4d-0 zeroed 19 106 stab 12\n",
      "coef tensor([3.1721, 0.7348, 0.6512, 1.5985, 2.8507, 0.6964, 1.4886, 1.2925, 2.0700,\n",
      "        0.4959, 1.9167, 1.3636, 1.4105, 1.9773, 1.9568, 0.2555, 0.6615, 0.7733,\n",
      "        1.6255, 2.4068, 2.7403, 0.2055, 2.5728, 1.1255, 1.5742, 2.6145, 2.2485,\n",
      "        0.2988, 0.7034, 0.9031, 1.2072, 0.5275, 0.4086, 1.4303, 2.0427, 2.1786,\n",
      "        2.8081, 1.6241, 2.5420, 0.2960, 0.4142, 2.9095, 2.4875, 2.6036, 2.6250,\n",
      "        2.2887, 1.9398, 0.5739, 1.5128, 2.2947, 1.9995, 0.2053, 1.7292, 0.1111,\n",
      "        2.6658, 2.1171, 1.7427, 1.1722, 2.3420, 1.4843, 1.9018, 1.7774, 1.3848,\n",
      "        1.5565, 1.0111, 1.2211, 1.5781, 1.3100, 2.2673, 1.1839, 2.6316, 1.0965,\n",
      "        2.3469, 2.0303, 0.4492, 0.4306, 1.4300, 2.2133, 1.8072, 0.4167, 0.3416,\n",
      "        1.8783, 0.3285, 0.4904, 2.2719, 1.2732, 1.9552, 0.4041, 2.7499, 2.0713,\n",
      "        2.3559, 2.6477, 0.3105, 1.6094, 2.0000, 1.0014, 1.7148, 0.5373, 2.5899,\n",
      "        2.4160, 0.9130, 1.4304, 2.7449, 2.5277, 1.1812, 0.2694])\n",
      "unif_coef tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "GET_IDEALIZED_MODEL 1d-0\n",
      "l diff tensor(0.0205)\n",
      "r diff tensor(0.0205)\n",
      "u diff tensor(0.0057)\n",
      "GET_IDEALIZED_MODEL 4d-0\n",
      "l diff tensor(1.)\n",
      "r diff tensor(1.)\n",
      "u diff tensor(0.)\n",
      "total\n",
      "l 1-r2 tensor(0.9594)\n",
      "r 1-r2 tensor(0.9594)\n",
      "u 1-r2 tensor(0.0003)\n",
      "bias 1-r2 tensor(0.5477)\n"
     ]
    }
   ],
   "source": [
    "model = models[13]\n",
    "irreps, irrep_idx_dict = get_neuron_irreps(model, group, norm_thresh=0.1)\n",
    "vecs, avar = get_neuron_vecs(model, group, irreps, irrep_idx_dict, strict=False, num_clusters=1, verbose=True, stab_thresh=0.3)\n",
    "# irrep_acc, irrep_time, all_zeroed = irrep_acc_bound(model, group, irreps, irrep_idx_dict, vecs)\n",
    "unif_vecs, zeroed_irreps = get_unif_vecs(group, irreps, vecs, verbose=True, stab_thresh=0.3)\n",
    "ideal, _ = get_idealized_model(model, irreps, irrep_idx_dict, unif_vecs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "908e4e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equivariance(ideal, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "61b6d6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "         -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "          1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal.unembed_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9a86e8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,\n",
       "           1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257,\n",
       "          -1.1257, -1.1257,  1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257,\n",
       "          -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "           1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,  1.1257,\n",
       "          -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "           1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,\n",
       "           1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          -1.1257,  1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,\n",
       "           1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,\n",
       "          -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257,\n",
       "          -1.1257, -1.1257,  1.1257,  1.1257, -1.1257,  1.1257, -1.1257,\n",
       "          -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,  1.1257,\n",
       "          -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,  1.1257,\n",
       "           1.1257, -1.1257, -1.1257,  1.1257,  1.1257, -1.1257, -1.1257,\n",
       "           1.1257]]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submodel(t.tensor([[0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9473f2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722,\n",
       "          -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,\n",
       "           1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,\n",
       "           1.1722,  1.1722, -1.1722,  1.1722, -1.1722, -1.1722,  1.1722,\n",
       "           1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,\n",
       "           1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722,\n",
       "          -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722, -1.1722,\n",
       "           1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722,\n",
       "          -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722,\n",
       "          -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,\n",
       "           1.1722, -1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722,\n",
       "          -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,\n",
       "           1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,\n",
       "           1.1722,  1.1722, -1.1722, -1.1722,  1.1722, -1.1722,  1.1722,\n",
       "           1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,\n",
       "           1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722, -1.1722,\n",
       "          -1.1722,  1.1722,  1.1722, -1.1722, -1.1722,  1.1722,  1.1722,\n",
       "          -1.1722]]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submodel(t.tensor([[15, 27]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed0b47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14400, 1, 120])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs = t.tensor(list(product(range(data.N), repeat=2)), device=device)\n",
    "models[0](test_inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03cc9b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groups[0].mult_idx(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "809c66e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 2],\n",
       "        [0, 3],\n",
       "        [0, 4],\n",
       "        [0, 5],\n",
       "        [0, 6],\n",
       "        [0, 7],\n",
       "        [0, 8],\n",
       "        [0, 9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262824d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group_addition-BDyFuYvs-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
